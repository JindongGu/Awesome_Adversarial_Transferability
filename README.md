
### What is Adversarial Transferability?

### Why Adversarial Transferability?


### Reference
- This repo lists relevant papers summarized in our survey paper.
  [[pdf]](https://arxiv.org/pdf/2111.11368.pdf)
  - Jindong Gu, Philip Torr (To edit)
 
* Abbreviation tag, e.g., ![](https://img.shields.io/badge/CLIP-CD6155?style=flat-square)  ![](https://img.shields.io/badge/data-4472C4) ![](https://img.shields.io/badge/model-7030A0) ![](https://img.shields.io/badge/loss-538C51) ![](https://img.shields.io/badge/optimization-D95E32) ![](https://img.shields.io/badge/generative-D94A70)
### Papers
#### 2022
- ![](https://img.shields.io/badge/data-4472C4) Improving the Transferability of Targeted Adversarial Examples through Object-Based Diverse Input.
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2022/papers/Byun_Improving_the_Transferability_of_Targeted_Adversarial_Examples_Through_Object-Based_Diverse_CVPR_2022_paper.pdf)
  [[code]](https://github.com/dreamflake/ODI)<br />
  Junyoung Byun, Seungju Cho, Myung-Joon Kwon, Hee-Seon Kim, Changick Kim. **CVPR**, 2022. 

- ![](https://img.shields.io/badge/loss-538C51) Investigating Top-k White-Box and Transferable Black-box Attack.
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Investigating_Top-k_White-Box_and_Transferable_Black-Box_Attack_CVPR_2022_paper.pdf)
  [[code]](https://github.com/ChaoningZhang/Top-k-Transferable-Attack)<br />
  Chaoning Zhang, Philipp Benz, Adil Karjauv, Jae Won Cho, Kang Zhang, In So Kweon. **CVPR**, 2022. 
  
- ![](https://img.shields.io/badge/optimization-D95E32) Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting the Adversarial Transferability.
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2022/papers/Xiong_Stochastic_Variance_Reduced_Ensemble_Adversarial_Attack_for_Boosting_the_Adversarial_CVPR_2022_paper.pdf)
  [[code]](https://github.com/JHL-HUST/SVRE)<br />
  Yifeng Xiong, Jiadong Lin, Min Zhang, John E. Hopcroft, Kun He. **CVPR**, 2022. 
  
- ![](https://img.shields.io/badge/loss-538C51) Cross-Modal Transferable Adversarial Attacks from Images to Videos.
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Cross-Modal_Transferable_Adversarial_Attacks_From_Images_to_Videos_CVPR_2022_paper.pdf)<br />
  Zhipeng Wei, Jingjing Chen, Zuxuan Wu, Yu-Gang Jiang. **CVPR**, 2022. 
  
- ![](https://img.shields.io/badge/loss-538C51) Improving Adversarial Transferability via Neuron Attribution-Based Attacks.
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Improving_Adversarial_Transferability_via_Neuron_Attribution-Based_Attacks_CVPR_2022_paper.pdf)
  [[code]](https://github.com/jpzhang1810/NAA)<br />
  Jianping Zhang, Weibin Wu, Jen-tse Huang, Yizhan Huang, Wenxuan Wang, Yuxin Su, Michael R. Lyu. **CVPR**, 2022. 

- ![](https://img.shields.io/badge/data-4472C4) Boosting the Transferability of Video Adversarial Examples via Temporal Translation.
  [[pdf]](https://arxiv.org/pdf/2110.09075.pdf)
  [[code]](https://github.com/zhipeng-wei/TT)<br />
  Zhipeng Wei, Jingjing Chen, Zuxuan Wu, Yu-Gang Jiang. **AAAI**, 2022.

- ![](https://img.shields.io/badge/data-4472C4) Transferable Adversarial Attack based on Integrated Gradients.
  [[pdf]](https://arxiv.org/pdf/2205.13152.pdf)<br />
  Yi Huang, Adams Wai-Kin Kong. arXiv, 2022.

- ![](https://img.shields.io/badge/optimization-D95E32) Making Adversarial Examples More Transferable and Indistinguishable.
  [[pdf]](https://arxiv.org/pdf/2007.03838v2.pdf)
  [[code]](https://github.com/278287847/AI-FGTM)<br />
  Junhua Zou, Yexin Duan, Boyu Li, Wu Zhang, Yu Pan, Zhisong Pan. **AAAI**, 2022.

- ![](https://img.shields.io/badge/optimization-D95E32) Boosting the Transferability of Adversarial Attacks with Reverse Adversarial Perturbation.
  [[pdf]](https://proceedings.neurips.cc/paper_files/paper/2022/file/c0f9419caa85d7062c7e6d621a335726-Paper-Conference.pdf)
  [[code]](https://github.com/SCLBD/Transfer_attack_RAP)<br />
  Zeyu Qin, Yanbo Fan, Yi Liu, Li Shen, Yong Zhang, Jue Wang, Baoyuan Wu. **NIPS**, 2022.

- ![](https://img.shields.io/badge/loss-538C51) Learning to Learn Transferable Attack.
  [[pdf]](https://ojs.aaai.org/index.php/AAAI/article/view/19936/19695)<br />
  Shuman Fang, Jie Li, Xianming Lin, Rongrong Ji. **AAAI**, 2022.

- ![](https://img.shields.io/badge/loss-538C51) Adversarially Robust Models may not Transfer Better:<br />Sufficient Conditions for Domain Transferability from the View of Regularization.
  [[pdf]](https://proceedings.mlr.press/v162/xu22n/xu22n.pdf)<br />
  Xiaojun Xu, Jacky Y Zhang, Evelyn Ma, Hyun Ho Son, Sanmi Koyejo, Bo Li. **ICML**, 2022. 

#### 2021
- ![](https://img.shields.io/badge/data-4472C4) Admix: Enhancing the Transferability of Adversarial Attacks.
  [[pdf]](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Admix_Enhancing_the_Transferability_of_Adversarial_Attacks_ICCV_2021_paper.pdf)
  [[code]](https://github.com/JHL-HUST/Admix)<br />
  Xiaosen Wang, Xuanran He, Jingdong Wang, Kun He. **ICCV**, 2021. 
  
- ![](https://img.shields.io/badge/generative-D94A70) On Generating Transferable Targeted Perturbations.
  [[pdf]](https://openaccess.thecvf.com/content/ICCV2021/papers/Naseer_On_Generating_Transferable_Targeted_Perturbations_ICCV_2021_paper.pdf)
  [[code]](https://github.com/Muzammal-Naseer/TTP)<br />
  Muzammal Naseer, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Fatih Porikli. **ICCV**, 2021. 
  
- ![](https://img.shields.io/badge/model-7030A0) Batch Normalization Increases Adversarial Vulnerability and Decreases Adversarial Transferability:  <br />A Non-Robust Feature Perspective.
  [[pdf]](https://openaccess.thecvf.com/content/ICCV2021/papers/Benz_Batch_Normalization_Increases_Adversarial_Vulnerability_and_Decreases_Adversarial_Transferability_A_ICCV_2021_paper.pdf) <br />
  Philipp Benz, Chaoning Zhang, In So Kweon. **ICCV**, 2021.

- ![](https://img.shields.io/badge/data-4472C4) Improving the Transferability of Adversarial Samples with Adversarial Transformations.
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Improving_the_Transferability_of_Adversarial_Samples_With_Adversarial_Transformations_CVPR_2021_paper.pdf)<br />
  Weibin Wu, Yuxin Su, Michael R. Lyu, Irwin King. **CVPR**, 2021.

- ![](https://img.shields.io/badge/optimization-D95E32) Enhancing the Transferability of Adversarial Attacks Through Variance Tuning.
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Enhancing_the_Transferability_of_Adversarial_Attacks_Through_Variance_Tuning_CVPR_2021_paper.pdf)
  [[code]](https://github.com/JHL-HUST/VT)<br />
  Xiaosen Wang, Kun He. **CVPR**, 2021.

- ![](https://img.shields.io/badge/loss-538C51) Improving Transferability of Adversarial Patches on Face Recognition With Generative Models.
  [[pdf]](https://openaccess.thecvf.com/content/CVPR2021/papers/Xiao_Improving_Transferability_of_Adversarial_Patches_on_Face_Recognition_With_Generative_CVPR_2021_paper.pdf)<br />
  Zihao Xiao, Xianfeng Gao, Chilin Fu, Yinpeng Dong, Wei Gao, Xiaolu Zhang, Jun Zhou, Jun Zhu. **CVPR**, 2021.

- ![](https://img.shields.io/badge/loss-538C51) On Success and Simplicity: A Second Look at Transferable Targeted Attacks.
  [[pdf]](https://proceedings.neurips.cc/paper_files/paper/2021/file/30d454f09b771b9f65e3eaf6e00fa7bd-Paper.pdf)
  [[code]](https://github.com/ZhengyuZhao/Targeted-Transfer)<br />
  Zhengyu Zhao, Zhuoran Liu, Martha Larson. **NIPS**, 2021.

- ![](https://img.shields.io/badge/loss-538C51) Learning Transferable Adversarial Perturbations.
  [[pdf]](https://proceedings.neurips.cc/paper_files/paper/2021/file/7486cef2522ee03547cfb970a404a874-Paper.pdf)<br />
  Krishna kanth Nakka, Mathieu Salzmann. **NIPS**, 2021.

#### 2020
- ![](https://img.shields.io/badge/data-4472C4) Adversarial Examples on Segmentation Models Can be Easy to Transfer.
  [[pdf]](https://arxiv.org/pdf/2111.11368.pdf)
  [[code]](https://arxiv.org/pdf/2111.11368.pdf)<br />
  Jindong Gu, Hengshuang Zhao, Volker Tresp, Philip Torr. arXiv, 2020.

- ![](https://img.shields.io/badge/data-4472C4) Improving the Transferability of Adversarial Examples with Resized-Diverse-Inputs, Diversity-Ensemble and Region Fitting.
  [[pdf]](https://arxiv.org/pdf/2112.06011.pdf)
  [[code]](https://github.com/278287847/DEM)<br />
  Junhua Zou, Zhisong Pan, Junyang Qiu, Xin Liu, Ting Rui, Wei Li. **ECCV**, 2020.

- ![](https://img.shields.io/badge/data-4472C4) Regional Homogeneity: Towards Learning Transferable Universal Adversarial Perturbations Against Defenses.
  [[pdf]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560766.pdf)
  [[code]](https://github.com/LiYingwei/Regional-Homogeneity)<br />
  Yingwei Li, Song Bai, Cihang Xie, Zhenyu Liao, Xiaohui Shen, Alan Yuille. **ECCV**, 2020.

- ![](https://img.shields.io/badge/loss-538C51) Towards Transferable Targeted Attack.
  [[pdf]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Towards_Transferable_Targeted_Attack_CVPR_2020_paper.pdf)
  [[code]](https://github.com/TiJoy/Towards-Transferable-Targeted-Attack)<br />
  Maosen Li, Cheng Deng, Tengjiao Li, Junchi Yan, Xinbo Gao, Heng Huang. **CVPR**, 2020. 

#### 2019
- ![](https://img.shields.io/badge/data-4472C4) Improving Transferability of Adversarial Examples with Input Diversity.
  [[pdf]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xie_Improving_Transferability_of_Adversarial_Examples_With_Input_Diversity_CVPR_2019_paper.pdf)
  [[code]](https://github.com/cihangxie/DI-2-FGSM)<br />
  Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou Ren, Alan L. Yuille. **CVPR**, 2019.

- ![](https://img.shields.io/badge/data-4472C4) Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks.
  [[pdf]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Dong_Evading_Defenses_to_Transferable_Adversarial_Examples_by_Translation-Invariant_Attacks_CVPR_2019_paper.pdf)
  [[code]](https://github.com/dongyp13/Translation-Invariant-Attacks)<br />
  Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu. **CVPR**, 2019.

- ![](https://img.shields.io/badge/optimization-D95E32) ![](https://img.shields.io/badge/data-4472C4) Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks.
  [[pdf]](https://arxiv.org/pdf/1908.06281.pdf)
  [[code]](https://github.com/JHL-HUST/SI-NI-FGSM)<br />
  Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft. arxiv, 2019.

- ![](https://img.shields.io/badge/loss-538C51) Enhancing Adversarial Example Transferability With an Intermediate Level Attack.
  [[pdf]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_Enhancing_Adversarial_Example_Transferability_With_an_Intermediate_Level_Attack_ICCV_2019_paper.pdf)
  [[code]](https://github.com/CUAI/Intermediate-Level-Attack)<br />
  Qian Huang, Isay Katsman, Horace He, Zeqi Gu, Serge Belongie, Ser-Nam Lim. **ICCV**, 2019.

#### 2018
- ![](https://img.shields.io/badge/loss-538C51) Task-generalizable Adversarial Attack based on Perceptual Metric.
  [[pdf]](https://arxiv.org/pdf/1811.09020.pdf)<br />
  Muzammal Naseer, Salman H. Khan, Shafin Rahman, Fatih Porikli, arxiv, 2018.

- ![](https://img.shields.io/badge/optimization-D95E32) Boosting Adversarial Attacks with Momentum.
  [[pdf]](https://openaccess.thecvf.com/content_cvpr_2018/papers/Dong_Boosting_Adversarial_Attacks_CVPR_2018_paper.pdf)
  [[code]](https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks)<br />
  Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, Jianguo Li. **CVPR**, 2018.

- ![](https://img.shields.io/badge/loss-538C51) Transferable Adversarial Perturbations.
  [[pdf]](https://openaccess.thecvf.com/content_ECCV_2018/papers/Bruce_Hou_Transferable_Adversarial_Perturbations_ECCV_2018_paper.pdf)<br />
  Wen Zhou, Xin Hou, Yongjun Chen, Mengyun Tang, Xiangqi Huang, Xiang Gan, Yong Yang. **ECCV**, 2018.
  
#### 2015
- ![](https://img.shields.io/badge/model-7030A0) Delving into Transferable Adversarial Examples and Black-box Attacks.
  [[pdf]](https://openreview.net/pdf?id=Sys6GJqxl)
  [[code]](https://github.com/sunblaze-ucb/transferability-advdnn-pub)<br />
  Yanpei Liu, Xinyun Chen, Chang Liu, Dawn Song, **ICLR**, 2015


### Contact

Please contact us (jindong.gu@outlook.com) if 
- you would like to add your paper in this repo,
- you find any mistake in this repo, 
- you have any suggestion for this repo. 

